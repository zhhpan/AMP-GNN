import logging
import os
import os.path as osp
from argparse import Namespace
from typing import Any, Dict, Tuple
import matplotlib.pyplot as plt
import numpy as np
import torch
from torch import Tensor
from torch.nn import CrossEntropyLoss
from torch_geometric.data import Data
from torch_geometric.loader import DataLoader
from torchmetrics import Accuracy
from tqdm import tqdm
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from dataset import DataSet as DS
from model import AMPGNN
from param import GumbelParameters, EnvironmentParameters, ActionParameters


class Experiment:

    def __init__(self, args: Namespace) -> None:
        """
        å®éªŒé…ç½®åˆå§‹åŒ–
        Args:
            args (Namespace): åŒ…å«ä»¥ä¸‹å…³é”®å‚æ•°ï¼š
                - dataset_name: æ•°æ®é›†åç§°
                - seed: éšæœºç§å­
                - batch_size: æ‰¹å¤§å°
                - env_dim: ç¯å¢ƒç½‘ç»œç»´åº¦
                - act_dim: åŠ¨ä½œç½‘ç»œç»´åº¦
                - dropout: ä¸¢å¼ƒç‡
                - lr: å­¦ä¹ ç‡
                - epochs: è®­ç»ƒè½®æ¬¡

        """
        # åˆå§‹åŒ–æ—¥å¿—é…ç½®
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            force=True
        )
        self.logger = logging.getLogger(__name__)

        # å‚æ•°æ³¨å…¥
        for param in vars(args):
            value = getattr(args, param)
            self.logger.info(f"åˆå§‹åŒ–å‚æ•° {param}: {value}")
            setattr(self, param, value)

        # è®¾å¤‡é…ç½®
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.logger.info(f"è¿è¡Œè®¾å¤‡: {self.device}")

        # åˆå§‹åŒ–éšæœºç§å­
        self.set_seed()

        # åˆå§‹åŒ–æ•°æ®é›†
        self.load_dataset()

        # åˆå§‹åŒ–ä»»åŠ¡æŸå¤±å‡½æ•°
        self.task_loss = CrossEntropyLoss()

        # è·å–æ‰€æœ‰æŠ˜å ç´¢å¼•
        self.folds = self.dataset.get_folds()

        # è·å–åˆ†ç±»ä»»åŠ¡ç±»åˆ«æ•°
        self.num_classes = self.dataset.get_out_dim()
        self.logger.info(f"åˆ†ç±»ç±»åˆ«æ•°: {self.num_classes}")

        # åˆå§‹åŒ–AccuracyæŒ‡æ ‡
        self.accuracy = Accuracy(
            task="multiclass",
            num_classes=self.num_classes
        ).to(self.device)

    def set_seed(self) -> None:
        """è®¾ç½®å…¨å±€éšæœºç§å­"""
        torch.manual_seed(self.seed)
        if torch.cuda.is_available():
            torch.cuda.manual_seed_all(self.seed)
        np.random.seed(self.seed)
        self.logger.info(f"å…¨å±€éšæœºç§å­è®¾ç½®ä¸º {self.seed}")

    def prepare_model_arguments(self) :
        """

        Returns:
            'gumbel': Gumbelå‚æ•°
            'env': ç¯å¢ƒç½‘ç»œå‚æ•°
            'action': è¡ŒåŠ¨ç½‘ç»œå‚æ•°
        """

        # Gumbelå‚æ•°
        gumbel_params = GumbelParameters(
            learn_temp = self.learn_temp,
            tau0 = self.tau0,
            temp = self.temp,
            gin_mlp_func = self.dataset.gin_mlp_func(),
            model_type = self.gumbel_model_type
        )

        # ç¯å¢ƒç½‘ç»œå‚æ•°ï¼ˆæ ¸å¿ƒç»„ä»¶ï¼‰
        env_params = EnvironmentParameters(
            num_layers = self.env_num_layers,
            env_dim = self.env_dim,
            in_dim = self.dataset.num_features,
            out_dim = self.dataset.get_out_dim(),
            dropout = self.dropout,
            activation = self.dataset.env_activation_type(),
            model_type = self.env_model_type
        )

        # è¡ŒåŠ¨ç½‘ç»œå‚æ•°
        action_params = ActionParameters(
            num_layers = self.act_num_layers,
            hidden_dim = self.act_dim,
            env_dim = self.env_dim,
            dropout = self.dropout,
            model_type = self.act_model_type
        )

        return gumbel_params, env_params, action_params

    def load_dataset(self) :
        """
            Returns:
                Data: åŒ…å«ä»¥ä¸‹å±æ€§çš„æ•°æ®å¯¹è±¡ï¼š
                    - x: èŠ‚ç‚¹ç‰¹å¾
                    - y: èŠ‚ç‚¹æ ‡ç­¾
                    - edge_index: å…¨è¿æ¥è¾¹ç´¢å¼•
                    - train_mask: è®­ç»ƒèŠ‚ç‚¹æ©ç 
                    - val_mask: éªŒè¯èŠ‚ç‚¹æ©ç 
                    - test_mask: æµ‹è¯•èŠ‚ç‚¹æ©ç 
        """
        # åˆå§‹åŒ–datasetçš„å‚æ•°å’Œå­˜å‚¨ä½ç½®
        ROOT_DIR = os.path.dirname(os.path.abspath(__file__))
        root = osp.join(ROOT_DIR, 'datasets')
        name = self.dataset_name
        # åŠ è½½æ•°æ®é›†
        self.dataset = DS(root=root, name=name)
        # ç±»å‹è½¬æ¢
        self.dataset.data.y = self.dataset.data.y.to(torch.long)

        return

    def create_data_loaders(self) -> Dict[str, DataLoader]:
        """
            åˆ›å»ºæ•°æ®åŠ è½½å™¨

            Returns:
                Dict: åŒ…å«ä¸‰ä¸ªæ•°æ®åŠ è½½å™¨ï¼š
                    'train': è®­ç»ƒé›†åŠ è½½å™¨
                    'val': éªŒè¯é›†åŠ è½½å™¨
                    'test': æµ‹è¯•é›†åŠ è½½å™¨
         """
        def apply_mask(data: Data, mask_type: str) -> Data:
            masked_data = data.clone()
            for node_type in ['train', 'val', 'test']:
                if node_type != mask_type:
                    setattr(masked_data, f"{node_type}_mask", None)
            return masked_data

        loaders = {
            'train': DataLoader([apply_mask(self.data, 'train')],
                                batch_size=self.batch_size, shuffle=False),
            'val': DataLoader([apply_mask(self.data, 'val')],
                              batch_size=self.batch_size, shuffle=False),
            'test': DataLoader([apply_mask(self.data, 'test')],
                               batch_size=self.batch_size, shuffle=False)
        }
        return loaders

    def calculate_loss(self, model: torch.nn.Module, data: Data, mask: str) -> Tensor:
        """
        è®¡ç®—äº¤å‰ç†µæŸå¤±

        Args:
            model: è®­ç»ƒä¸­çš„æ¨¡å‹
            data: å½“å‰æ‰¹æ¬¡æ•°æ®
            mask: ä½¿ç”¨çš„æ©ç åç§°ï¼ˆtrain/val/testï¼‰

        Returns:
            Tensor: è®¡ç®—å¾—åˆ°çš„æŸå¤±å€¼
        """
        # è·å–èŠ‚ç‚¹æ©ç 
        node_mask = getattr(data, f"{mask}_mask")

        # å‰å‘ä¼ æ’­
        out = model(data.x.to(self.device),
                    data.edge_index.to(self.device))

        # è®¡ç®—æŸå¤±
        loss = self.task_loss(out[node_mask], data.y.to(self.device)[node_mask])
        return loss

    def evaluate(self, model: torch.nn.Module, loader: DataLoader, mask: str) -> Tuple[float, float]:
        """æ¨¡å‹è¯„ä¼°"""
        model.eval()
        total_loss = 0
        correct = 0

        with torch.no_grad():
            for data in loader:
                loss = self.calculate_loss(model, data, mask)
                total_loss += loss.item()

                pred = model(data.x.to(self.device),
                             data.edge_index.to(self.device)).argmax(dim=1)
                # correct += pred.eq(data.y.to(self.device)).sum().item()
                node_mask = getattr(data, f"{mask}_mask")
                self.accuracy(pred, data.y.to(self.device))

        avg_loss = total_loss / len(loader)
        #accuracy = correct / len(loader.dataset[0].y)
        accuracy = self.accuracy.compute().item()
        return avg_loss, accuracy

    def run(self) -> Dict[str, Any]:
        """æ‰§è¡Œ10æŠ˜äº¤å‰éªŒè¯æµç¨‹ï¼ˆé›†æˆåŠ¨æ€æŸå¤±å›¾ï¼‰"""
        fold_results = []
        total_steps = len(self.folds) * self.epochs

        # åˆ›å»ºä¸»è¿›åº¦æ¡
        with tqdm(total=total_steps, desc="ğŸŒ åˆå§‹åŒ–è®­ç»ƒè¿›åº¦...") as pbar:
            for fold in range(len(self.folds)):
                # åˆå§‹åŒ–æŠ˜å ç›¸å…³å˜é‡
                data_fold = self.dataset.select_fold_and_split(fold)
                self.data = data_fold
                loaders = self.create_data_loaders()

                # åˆå§‹åŒ–æ¨¡å‹
                gumbel_params, env_params, action_params = self.prepare_model_arguments()
                model = AMPGNN(gumbel_params, env_params, action_params, self.device).to(self.device)
                optimizer = torch.optim.Adam(model.parameters(), lr=self.lr, weight_decay=5e-4)

                # åˆå§‹åŒ–æœ¬æŠ˜å çš„æŸå¤±è®°å½•
                train_losses = []
                val_losses = []
                best_acc = 0

                # åˆ›å»ºåŠ¨æ€å›¾è¡¨
                fig = make_subplots(rows=1, cols=1)
                fig.add_trace(go.Scatter(
                    x=[],
                    y=[],
                    mode='lines',
                    name='Train Loss',
                    line=dict(color='blue')
                ), row=1, col=1)
                fig.add_trace(go.Scatter(
                    x=[],
                    y=[],
                    mode='lines',
                    name='Val Loss',
                    line=dict(color='red')
                ), row=1, col=1)
                fig.update_layout(
                    title=f'Fold {fold + 1} Training Progress',
                    xaxis_title='Epoch',
                    yaxis_title='Loss',
                    showlegend=True,
                    template='plotly_white'
                )

                # åˆå§‹åŒ–HTMLæ–‡ä»¶è·¯å¾„
                html_path = f'result/training_fold_{fold+1}.html'
                fig.write_html(html_path, auto_open=False)

                for epoch in range(self.epochs):
                    # è®­ç»ƒæ­¥éª¤
                    model.train()
                    optimizer.zero_grad()
                    train_loss = self.calculate_loss(model, self.data, 'train')
                    train_loss.backward()
                    optimizer.step()

                    # éªŒè¯æ­¥éª¤
                    model.eval()
                    with torch.no_grad():
                        val_loss, val_acc = self.evaluate(model, loaders['val'], 'val')
                    self.accuracy.reset()

                    # è®°å½•æŸå¤±
                    train_losses.append(train_loss.item())
                    val_losses.append(val_loss)

                    # åŠ¨æ€æ›´æ–°å›¾è¡¨ï¼ˆæ¯50ä¸ªepochæ›´æ–°ä¸€æ¬¡ï¼‰
                    if epoch % 50 == 0 or epoch == self.epochs - 1:
                        # æ›´æ–°å›¾è¡¨æ•°æ®
                        fig.update_traces(
                            x=np.arange(len(train_losses)),
                            y=train_losses,
                            selector={'name': 'Train Loss'}
                        )
                        fig.update_traces(
                            x=np.arange(len(val_losses)),
                            y=val_losses,
                            selector={'name': 'Val Loss'}
                        )

                        # è‡ªåŠ¨è°ƒæ•´åæ ‡è½´èŒƒå›´
                        fig.update_xaxes(range=[0, self.epochs])
                        y_max = max(max(train_losses), max(val_losses)) * 1.1
                        fig.update_yaxes(range=[0, y_max])

                        # ä¿å­˜æ›´æ–°åçš„å›¾è¡¨
                        fig.write_html(html_path, auto_open=False)

                    # æ›´æ–°æœ€ä½³æ¨¡å‹
                    if val_acc > best_acc:
                        best_acc = val_acc
                        torch.save(model.state_dict(), f'fold/{self.dataset.name}_fold{fold}.pth')

                    # æ›´æ–°è¿›åº¦æ¡
                    desc = (f"\033[32mğŸŒ Fold {fold + 1}/{len(self.folds)} | "
                            f"\033[34mEpoch {epoch + 1}/{self.epochs} | "
                            f"Train: {train_loss.item():.4f} | "
                            f"Val: {val_loss:.4f} | "
                            f"Best Val Acc: {best_acc:.2%}")
                    pbar.set_description(desc)
                    pbar.update(1)

                # æŠ˜å ç»“æŸåæ˜¾ç¤ºæœ€ç»ˆç»“æœ
                model.load_state_dict(torch.load(f'fold/{self.dataset.name}_fold{fold}.pth'))
                test_loss, test_acc = self.evaluate(model, loaders['test'], 'test')
                fold_results.append(test_acc)

                # æ·»åŠ æœ€ç»ˆæ ‡æ³¨
                fig.add_annotation(
                    xref="paper", yref="paper",
                    x=0.95, y=0.95,
                    text=f"Final Test Acc: {test_acc:.2%}",
                    showarrow=False,
                    font=dict(size=12)
                )
                fig.write_html(html_path, auto_open=False)
                print(f"\nâœ… Fold {fold+1} è®­ç»ƒå®Œæˆï¼Œå›¾è¡¨å·²ä¿å­˜è‡³ {html_path}")

        # ç”Ÿæˆæœ€ç»ˆç»Ÿè®¡å›¾è¡¨
        final_fig = go.Figure()
        final_fig.add_trace(go.Bar(
            x=[f'Fold {i+1}' for i in range(len(fold_results))],
            y=fold_results,
            marker_color='rgb(55, 83, 109)'
        ))
        final_fig.update_layout(
            title='10-Fold Cross Validation Results',
            xaxis_title='Fold',
            yaxis_title='Accuracy',
            yaxis_tickformat=".2%",
            annotations=[
                dict(
                    x=0.5,
                    y=-0.15,
                    showarrow=False,
                    text=f"Mean Accuracy: {np.mean(fold_results):.2%} Â± {np.std(fold_results):.2%}",
                    xref="paper",
                    yref="paper"
                )
            ]
        )
        final_fig.write_html('result/final_results.html', auto_open=True)

        # ç»Ÿè®¡ç»“æœ
        test_accs = torch.tensor(fold_results)
        return {
            'fold_accs': test_accs.tolist(),
            'mean_acc': test_accs.mean().item(),
            'std_acc': test_accs.std().item(),
            'max_acc': test_accs.max().item(),
            'min_acc': test_accs.min().item()
        }


# ç¤ºä¾‹ç”¨æ³•
if __name__ == "__main__":
    # åˆå§‹åŒ–å‚æ•°
    args = Namespace(
        dataset_name='roman-empire',
        seed=0,
        batch_size=32,
        env_dim=64,
        act_dim=16,
        dropout=0.2,
        lr=0.001,
        epochs=10000,
        learn_temp=True,
        tau0 = 0.5,
        temp = 0.01,
        env_num_layers = 6,
        act_num_layers = 1 ,
        env_model_type = 'MEAN_GNN',
        act_model_type = 'MEAN_GNN',
        gumbel_model_type = 'LIN'
    )

    # è¿è¡Œå®éªŒ
    experiment = Experiment(args)
    results = experiment.run()

    print(f"10æŠ˜äº¤å‰éªŒè¯ç»“æœ:")
    print(f"å¹³å‡å‡†ç¡®ç‡: {results['mean_acc']:.2%} Â± {results['std_acc']:.2%}")
    print(f"æœ€ä½³æŠ˜å : {results['max_acc']:.2%}")
    print(f"æœ€å·®æŠ˜å : {results['min_acc']:.2%}")