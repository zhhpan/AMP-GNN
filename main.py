import os
from argparse import Namespace
from typing import Any, Dict, Tuple, Optional
import numpy as np
import torch
from torch import Tensor
from torch.nn import CrossEntropyLoss
from torch_geometric.data import Data
from torch_geometric.loader import DataLoader
import logging
import os.path as osp

from tqdm import tqdm

from dataset import DataSet as DS
from model import CoGNN


class Experiment:

    def __init__(self, args: Namespace) -> None:
        """
        å®éªŒé…ç½®åˆå§‹åŒ–
        Args:
            args (Namespace): åŒ…å«ä»¥ä¸‹å…³é”®å‚æ•°ï¼š
                - dataset_name: æ•°æ®é›†åç§°
                - seed: éšæœºç§å­ï¼ˆé»˜è®¤42ï¼‰
                - batch_size: æ‰¹å¤§å°
                - env_dim: ç¯å¢ƒç½‘ç»œç»´åº¦ï¼ˆé»˜è®¤64ï¼‰
                - act_dim: è¡ŒåŠ¨ç½‘ç»œç»´åº¦ï¼ˆé»˜è®¤32ï¼‰
                - dropout: ä¸¢å¼ƒç‡ï¼ˆé»˜è®¤0.5ï¼‰
                - lr: å­¦ä¹ ç‡ï¼ˆé»˜è®¤0.001ï¼‰
                - epochs: è®­ç»ƒè½®æ¬¡ï¼ˆé»˜è®¤3000ï¼‰

        """
        # åˆå§‹åŒ–æ—¥å¿—é…ç½®
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            force=True
        )
        self.logger = logging.getLogger(__name__)

        # å‚æ•°æ³¨å…¥
        for param in vars(args):
            value = getattr(args, param)
            self.logger.info(f"åˆå§‹åŒ–å‚æ•° {param}: {value}")
            setattr(self, param, value)

        # è®¾å¤‡é…ç½®
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.logger.info(f"è¿è¡Œè®¾å¤‡: {self.device}")

        # åˆå§‹åŒ–éšæœºç§å­
        self.set_seed()

        # åˆå§‹åŒ–æ•°æ®é›†
        self.load_dataset()

        # åˆå§‹åŒ–ä»»åŠ¡æŸå¤±å‡½æ•°
        self.task_loss = CrossEntropyLoss()

        # è·å–æ‰€æœ‰æŠ˜å ç´¢å¼•
        self.folds = self.dataset.get_folds()

    def set_seed(self) -> None:
        """è®¾ç½®å…¨å±€éšæœºç§å­"""
        torch.manual_seed(self.seed)
        if torch.cuda.is_available():
            torch.cuda.manual_seed_all(self.seed)
        np.random.seed(self.seed)
        self.logger.info(f"å…¨å±€éšæœºç§å­è®¾ç½®ä¸º {self.seed}")

    def prepare_model_arguments(self) -> Dict[str, Dict]:
        """

        Returns:
            Dict: åŒ…å«ä¸‰ä¸ªå‚æ•°å­—å…¸ï¼š
                'gumbel': Gumbelå‚æ•°
                'env': ç¯å¢ƒç½‘ç»œå‚æ•°
                'action': è¡ŒåŠ¨ç½‘ç»œå‚æ•°
        """
        # Gumbelå‚æ•°
        gumbel_params = {
            'learn_temp': self.learn_temp,
            'tau0': self.tau0,
            'temp': self.temp,
            'gin_mlp_func': self.dataset.gin_mlp_func(),
            'model_type': self.env_model_type
        }

        # ç¯å¢ƒç½‘ç»œå‚æ•°ï¼ˆæ ¸å¿ƒç»„ä»¶ï¼‰
        env_params = {
            'num_layers': self.env_num_layers,
            'env_dim': self.env_dim,
            'in_dim': self.dataset.num_features,
            'out_dim': self.dataset.get_out_dim(),
            'dropout': self.dropout,
            'activation': self.dataset.env_activation_type(),
            'model_type' : self.env_model_type
        }

        # è¡ŒåŠ¨ç½‘ç»œå‚æ•°
        action_params = {
            'num_layers': self.act_num_layers,
            'hidden_dim': self.act_dim,
            'env_dim': self.env_dim,
            'dropout': self.dropout,
            'model_type': self.act_model_type
        }

        return gumbel_params, env_params, action_params

    def load_dataset(self) -> Data:
        """

        Returns:
            Data: åŒ…å«ä»¥ä¸‹å±æ€§çš„æ•°æ®å¯¹è±¡ï¼š
                - x: èŠ‚ç‚¹ç‰¹å¾
                - y: èŠ‚ç‚¹æ ‡ç­¾
                - edge_index: å…¨è¿æ¥è¾¹ç´¢å¼•
                - train_mask: è®­ç»ƒèŠ‚ç‚¹æ©ç 
                - val_mask: éªŒè¯èŠ‚ç‚¹æ©ç 
                - test_mask: æµ‹è¯•èŠ‚ç‚¹æ©ç 
        """
        # åˆå§‹åŒ–datasetçš„å‚æ•°å’Œå­˜å‚¨ä½ç½®
        ROOT_DIR = os.path.dirname(os.path.abspath(__file__))
        root = osp.join(ROOT_DIR, 'datasets')
        name = self.dataset_name
        # åŠ è½½æ•°æ®é›†
        self.dataset = DS(root=root, name=name)
        # ç±»å‹è½¬æ¢
        self.dataset.data.y = self.dataset.data.y.to(torch.long)

        return self.dataset.data

    def create_data_loaders(self) -> Dict[str, DataLoader]:
        """
            åˆ›å»ºæ•°æ®åŠ è½½å™¨

            Returns:
                Dict: åŒ…å«ä¸‰ä¸ªæ•°æ®åŠ è½½å™¨ï¼š
                    'train': è®­ç»ƒé›†åŠ è½½å™¨
                    'val': éªŒè¯é›†åŠ è½½å™¨
                    'test': æµ‹è¯•é›†åŠ è½½å™¨
         """
        def apply_mask(data: Data, mask_type: str) -> Data:
            masked_data = data.clone()
            for node_type in ['train', 'val', 'test']:
                if node_type != mask_type:
                    setattr(masked_data, f"{node_type}_mask", None)
            return masked_data

        loaders = {
            'train': DataLoader([apply_mask(self.data, 'train')],
                                batch_size=self.batch_size, shuffle=False),
            'val': DataLoader([apply_mask(self.data, 'val')],
                              batch_size=self.batch_size, shuffle=False),
            'test': DataLoader([apply_mask(self.data, 'test')],
                               batch_size=self.batch_size, shuffle=False)
        }
        return loaders

    def calculate_loss(self, model: torch.nn.Module, data: Data, mask: str) -> Tensor:
        """
        è®¡ç®—äº¤å‰ç†µæŸå¤±

        Args:
            model: è®­ç»ƒä¸­çš„æ¨¡å‹
            data: å½“å‰æ‰¹æ¬¡æ•°æ®
            mask: ä½¿ç”¨çš„æ©ç åç§°ï¼ˆtrain/val/testï¼‰

        Returns:
            Tensor: è®¡ç®—å¾—åˆ°çš„æŸå¤±å€¼
        """
        # è·å–èŠ‚ç‚¹æ©ç 
        node_mask = getattr(data, f"{mask}_mask")

        # å‰å‘ä¼ æ’­
        out = model(data.x.to(self.device),
                    data.edge_index.to(self.device))

        # è®¡ç®—æŸå¤±
        loss = self.task_loss(out[node_mask], data.y.to(self.device)[node_mask])
        return loss

    def evaluate(self, model: torch.nn.Module, loader: DataLoader, mask: str) -> Tuple[float, float]:
        """æ¨¡å‹è¯„ä¼°"""
        model.eval()
        total_loss = 0
        correct = 0

        with torch.no_grad():
            for data in loader:
                loss = self.calculate_loss(model, data, mask)
                total_loss += loss.item()

                pred = model(data.x.to(self.device),
                             data.edge_index.to(self.device)).argmax(dim=1)
                correct += pred.eq(data.y.to(self.device)).sum().item()

        avg_loss = total_loss / len(loader)
        accuracy = correct / len(loader.dataset[0].y)
        return avg_loss, accuracy

    def run(self) -> Dict[str, Any]:
        """æ‰§è¡Œ10æŠ˜äº¤å‰éªŒè¯æµç¨‹"""
        fold_results = []
        total_steps = len(self.folds) * self.epochs

        # åˆ›å»ºä¸»è¿›åº¦æ¡ï¼ˆæ€»æ­¥æ•°=æŠ˜å æ•°Ã—epochæ•°ï¼‰
        with tqdm(
                total=total_steps,
                desc="ğŸŒ åˆå§‹åŒ–è®­ç»ƒè¿›åº¦...",  # åˆå§‹æè¿°
                bar_format="{desc}  [å·²ç”¨:{elapsed} å‰©ä½™:{remaining}]",
                mininterval=0.5  # é™ä½åˆ·æ–°é¢‘ç‡
        ) as pbar:
            print("")
            for fold in range(len(self.folds)):
                # åˆå§‹åŒ–å½“å‰æŠ˜å 
                data_fold = self.dataset.select_fold_and_split(fold)
                self.data = data_fold
                loaders = self.create_data_loaders()

                # åˆå§‹åŒ–æ¨¡å‹
                gumbel_params, env_params, action_params = self.prepare_model_arguments()
                model = CoGNN(gumbel_params, env_params, action_params, self.device).to(self.device)
                optimizer = torch.optim.Adam(model.parameters(), lr=self.lr, weight_decay=5e-4)

                best_acc = 0
                for epoch in range(self.epochs):
                    # è®­ç»ƒæ­¥éª¤
                    model.train()
                    optimizer.zero_grad()
                    loss = self.calculate_loss(model, self.data, 'train')
                    loss.backward()
                    optimizer.step()

                    # éªŒè¯æ­¥éª¤ï¼ˆæ¯10ä¸ªepochéªŒè¯ä¸€æ¬¡ï¼‰
                    if epoch % 10 == 0 or epoch == self.epochs - 1:
                        model.eval()
                        with torch.no_grad():
                            _, val_acc = self.evaluate(model, loaders['val'], 'val')

                        # æ›´æ–°æœ€ä½³æ¨¡å‹
                        if val_acc > best_acc:
                            best_acc = val_acc
                            torch.save(model.state_dict(), f'fold/{self.dataset.name}_fold{fold}.pth')

                    # åŠ¨æ€æ›´æ–°è¿›åº¦æ¡æè¿°
                    desc = (
                        f"\033[32mğŸŒ æŠ˜å Fold {fold + 1}/{len(self.folds)}\033[0m | "
                        f"\033[34mè½®æ¬¡Epoch {epoch + 1}/{self.epochs}\033[0m | "
                        f"æŸå¤±: \033[31m{loss.item():.4f}\033[0m | "
                        f"æœ€ä½³éªŒè¯: \033[33m{best_acc:.2%}\033[0m"
                    )
                    pbar.set_description(desc)
                    pbar.update(1)

                # æŠ˜å è®­ç»ƒå®Œæˆï¼Œæ‰§è¡Œæµ‹è¯•
                model.load_state_dict(torch.load(f'fold/{self.dataset.name}_fold{fold}.pth'))
                _, test_acc = self.evaluate(model, loaders['test'], 'test')
                fold_results.append(test_acc)

                # æ›´æ–°æœ€ç»ˆç»“æœå±•ç¤º
                pbar.write(
                    f"\nâœ… Fold {fold + 1} Completed | "
                    f"Test Accuracy: {test_acc:.2%} | "
                    f"Current Mean: {np.mean(fold_results):.2%}"
                )

        # ç»Ÿè®¡ç»“æœ
        test_accs = torch.tensor(fold_results)
        return {
            'fold_accs': test_accs.tolist(),
            'mean_acc': test_accs.mean().item(),
            'std_acc': test_accs.std().item(),
            'max_acc': test_accs.max().item(),
            'min_acc': test_accs.min().item()
        }


# ç¤ºä¾‹ç”¨æ³•
if __name__ == "__main__":
    # åˆå§‹åŒ–å‚æ•°
    args = Namespace(
        dataset_name='roman-empire',
        seed=0,
        batch_size=32,
        env_dim=64,
        act_dim=16,
        dropout=0.2,
        lr=0.001,
        epochs=3000,
        learn_temp=True,
        tau0 = 0.5,
        temp = 0.01,
        env_num_layers = 3,
        act_num_layers = 1 ,
        env_model_type = 'GIN',
        act_model_type = 'GCN',
    )

    # è¿è¡Œå®éªŒ
    experiment = Experiment(args)
    results = experiment.run()

    print(f"10æŠ˜äº¤å‰éªŒè¯ç»“æœ:")
    print(f"å¹³å‡å‡†ç¡®ç‡: {results['mean_acc']:.2%} Â± {results['std_acc']:.2%}")
    print(f"æœ€ä½³æŠ˜å : {results['max_acc']:.2%}")
    print(f"æœ€å·®æŠ˜å : {results['min_acc']:.2%}")